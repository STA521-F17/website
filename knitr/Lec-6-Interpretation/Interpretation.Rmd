---
title: "Interpretation, Prediction and Confidence Intervals"
author: "Merlise Clyde"
date: "September 15, 2017"
output: 
   beamer_presentation:
          increment: false
          includes:
             in_header:  macros.tex
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
suppressMessages(library(dplyr))
#suppressMessages(library(magrittr))
library(knitr)
library(MASS)
data(Animals)
Animals = 
  Animals %>%
    mutate(name = row.names(Animals)) %>%
    mutate(Dino.T = (name ==  "Triceratops")) %>%
    mutate(Dino.D = (name == "Dipliodocus")) %>%
    mutate(Dino.B = (name == "Brachiosaurus")) %>%
    mutate(Dino = (name %in% 
                   c("Triceratops",
                     "Brachiosaurus", 
                     "Dipliodocus")))
brain1.lm = lm(log(brain) ~ log(body),data=Animals) #0
brain2.lm = lm(log(brain) ~ log(body) + Dino,data=Animals) #1
brain3.lm = lm(log(brain) ~ log(body)*Dino, data=Animals) #2
brain4.lm = lm(log(brain) ~ log(body) + 
              Dino.T + Dino.B + Dino.D, data=Animals)  #3

```


## Last Class

Model for log  brain weight as a function of log body weight

- Nested Model Comparison using ANOVA led to model with parallel lines

- Why does model with the 3 indicator variable contain the other models?

$\log(brain) = \beta_0 +  \log(body) \beta_1+ \text{Dino.T} \beta_2 + \text{Dino.B} \beta_3 + \text{Dino.D}\beta_4  + \epsilon$


##  Check residuals

```{r}
par(mfrow=c(2,2))
plot(brain2.lm)
```

## Coefficient Summaries
```{r, results='asis', message=FALSE}
library(xtable)
print(xtable(coefficients(summary(brain2.lm))), comment=FALSE)
```


##  Distribution of Coefficients

* Joint Distribution under normality
 $$\hat{\b} \mid \sigma^2 \sim \N(\b, \sigma^2 (\X^T
   \X)^{-1})$$

* Distribution of SSE
$$\SSE/\sigma^2 \sim \chi^2(n-p)$$

* Marginal distribution
$$\frac{\hat{\beta}_j - \beta_j }
  {\text{SE}(\hat{\beta}_j)} \sim \St(n - p)$$
$$   {\text{SE}(\hat{\beta}_j)} = \hat{\sigma} \sqrt{ [\X^T\X]^{-1}]_{jj}]}$$
$$   \hat{\sigma}^2 = \frac{\SSE}{n-p}$$

## Confidence Intervals

$(1 - \alpha/2) 100$% Confidence interval for $\beta_j$
$$\hat{\beta}_j \pm t_{n-p, \alpha/2} 
  {\text{SE}(\hat{\beta}_j)}$$

```{r confint, echo=TRUE}
kable(confint(brain2.lm))


```

##  Converting to Original Units

* Model after exponentiating
\begin{align*}
\widehat{brain} & = e^{\hat{\beta}_0 +  \log(body) \hat{\beta}_1+  \text{Dino}\hat{\beta}_2} \\ 
 & = e^{\hat{\beta}_0} e^{\log(body) \hat{\beta}_1} e^{\text{Dino}\hat{\beta}_2}  \\ 
 & = e^{\hat{\beta}_0} body^{\hat{\beta}_1} e^{\text{Dino}\hat{\beta}_2}  
\end{align*}

* 10% increase in body weight implies a 
\begin{align*}
\widehat{brain}_{1.10} & = e^{\hat{\beta}_0} (1.10* body)^{\hat{\beta}_1} e^{\text{Dino}\hat{\beta}_2}   \\
 & = 1.10^{\hat{\beta}_1} e^{\hat{\beta}_0} body^{\hat{\beta}_1} e^{\text{Dino}\hat{\beta}_2} 
\end{align*}

* $1.1^{\hat{\beta}_1}$ = `r round(1.1^(coef(brain2.lm)[2]),3)` or a `r (  round(1.1^(coef(brain2.lm)[2]),3) -1)*100`% increase in brain weight

## 95% Confidence interval

To obtain a 95\% confidence interval, $(1.10^{CI} -1)*100$
```{r}
CI = confint(brain2.lm)[2, , drop=F]
rownames(CI) = "body"
kable(100*(1.1^CI -1))
```

## Interpretation of Intercept

* Evalutate model with predictors = 0
$$\widehat{\log(brain)} = \hat{\beta}_0 +  \log(body) \hat{\beta}_1+  \text{Dino}\hat{\beta}_2$$

* For a non-dinosaur, if `log(body) = 0`  (body weight = 1 kilogram), we expect that brain weight will be `r round(coef(brain2.lm)[1], 2)` log(grams) ???

* Exponentiate: predicted brain weight for non-dinosaur with a 1 kg body weight is 
$$e^{\hat{\beta}_0} =  `r round(exp(coef(brain2.lm)[1]), 2)` \text{ grams}$$



## Plot of Fitted Values
```{r pred.plot, echo=TRUE}
library(ggplot2)
beta= coef(brain2.lm)
gp = ggplot(Animals, aes(y=log(brain), x=log(body))) + 
     geom_point(aes(colour=factor(Dino))) +
     geom_abline(aes(intercept=beta[1], slope=beta[2])) +
     geom_abline(aes(intercept=(beta[1]+beta[3]), 
                     slope=beta[2]))
```
##  Plot of Fitted Values

```{r}
print(gp)
```

## Confidence Intervals for the $f(x)$

* Point Estimate
$$\widehat{f(x)} =  \x^T\bhat$$
* Distribution of MLE given $\sigma$
$$\widehat{f(x)} \sim \N(f(x), \sigma^2\x^T(\X^T\X)^{-1}\x)$$ 

* Distribution of pivotal quantity
$$\frac{\widehat{f(x)} - f(x)}{ \sqrt{\hat{\sigma}^2\x^T(\X^T\X)^{-1}\x}} \sim t(n-p)$$
* Confidence interval 
$$ \widehat{f(x)} \pm t_{\alpha/2}\sqrt{\hat{\sigma}^2\x^T(\X^T\X)^{-1}\x}$$


## Prediction Intervals for $Y_*$ at $\x_*$

* Model
$$Y_* = \x^T_* \b + \epsilon_*$$
* $Y_*$ independent of other $Y$'s

* Prediction error
$$Y_* - \widehat{f(x)} =  \x^T_* \b  -  \widehat{f(x_*)} + \epsilon_*$$

* Variance
\begin{align*}
\Var(Y_* - \widehat{f(x)}) & =  \Var(\x^T_* \b  -  \widehat{f(x_*)}) + \Var(\epsilon_*) \\
 & = \sigma^2 \x_*^T(\X^T\X)^{-1}\x_* + \sigma^2 \\
 & = \sigma^2(1 + \x_*^T(\X^T\X)^{-1}\x_*)
\end{align*}

* Prediction Intervals
$$ \widehat{f(x)} \pm t_{\alpha/2}\sqrt{\hat{\sigma}^2(1 + \x_*^T(\X^T\X)^{-1}\x_*})$$


##  Predictions  for 259 gram cockatoo
```{r pred}
newdata = data.frame(body=.0259, Dino=FALSE)
pred = predict(brain2.lm, newdata=newdata, se=T, interval="predict")

gp = gp + geom_segment(aes(y=pred$fit[2], yend=pred$fit[3],
                           x=log(.0259), xend=log(.0259)))
print(gp)
```

## Predictions in original units

* 95% Confidence Interval for $f(x)$
```{r CI, echo=T}
newdata = data.frame(body=.0259, Dino=FALSE)
fit = predict(brain2.lm, newdata=newdata,
              interval="confidence", se=T)
```

* 95% Prediction Interval for Brain Weight
```{r PI, echo=T}
pred = predict(brain2.lm, newdata=newdata, 
               interval="predict", se=T)
```


## CI/Predictions in original units for body=259 g

* 95% Confidence Interval for $f(x)$
```{r CI-val, echo=T}
exp(fit$fit)
```

* 95% Prediction Interval for Brain Weight
```{r PI-val, echo=T}
exp(pred$fit)
```

* 95% confident that the brain weight will be between 
`r round(exp(pred$fit[2]),2)` and `r round(exp(pred$fit[3]),2)` grams


## Summary

* Linear predictors may be based on functions of other predictors
(dummy variables, interactions, non-linear terms)

* need to change back to original units

* log transform useful for non-negative responses (ensures predictions are non-negative)

* Be careful of units of data 
      +  plots should show units
      +  summary statements should include units
      
* Goodness of fit measure: $R^2$ and Adjusted $R^2$  depend on scale   $R^2$ is percent variation in "$Y$" that is explained by the model
$$  R^2 = 1 - SSE/SST$$
where SST = $\sum_i (Y_i - \bar{Y})^2$


